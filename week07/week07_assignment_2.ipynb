{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 Assignment\n",
    "\n",
    "_MkKinney 6.1_\n",
    "\n",
    "This week has been all about getting information off the internet both in structured data formats (CSV, JSON, etc) as well as HTML.  For these exercises, we're going to use two practical examples of fetching data from web pages to show how to use Pandas and BeautifulSoup to extract structured information from the web.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33.1 Parsing a list in HTML\n",
    "\n",
    "Go to the Banner Health Price Transparency Page: https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency\n",
    "\n",
    "Notice that there is a list of hospitals and the city they are in.  We want to parse the underlying HTML to create a list of all the hospitals along with which city they're in.\n",
    "\n",
    "```json\n",
    "[\n",
    "    [\"Banner - University Medical Center Phoenix\", \"Arizona\"],\n",
    "    [\"Banner - University Medical Center South \", \"Arizona\"],\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "To examine the underlying HTML code, you can use Chrome, right-click, and choose **Inspect**.\n",
    "\n",
    "For reference, the documentation for BeautifulSoup is here: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, create a function called **parse_banner(url)** that takes as it's one parameter the URL of the webpage to be parsed for links.  Make sure you include docstrings and a good test case using hte URL provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Banner - University Medical Center Phoenix\",\"Arizona\"\n",
      "\"Banner - University Medical Center South \",\"Arizona\"\n",
      "\"Banner - University Medical Center Tucson\",\"Arizona\"\n",
      "\"Banner Baywood Medical Center \",\"Arizona\"\n",
      "\"Banner Behavioral Health Hospital\",\"Arizona\"\n",
      "\"Banner Boswell Medical Center\",\"Arizona\"\n",
      "\"Banner Casa Grande Medical Center\",\"Arizona\"\n",
      "\"Banner Del E. Webb Medical Center\",\"Arizona\"\n",
      "\"Banner Desert Medical Center/Cardon Children's Medical Center  \",\"Arizona\"\n",
      "\"Banner Estrella Medical Center\",\"Arizona\"\n",
      "\"Banner Gateway Medical Center/Banner MD Anderson Cancer Center\",\"Arizona\"\n",
      "\"Banner Goldfield Medical Center  \",\"Arizona\"\n",
      "\"Banner Heart Hospital\",\"Arizona\"\n",
      "\"Banner Ironwood Medical Center\",\"Arizona\"\n",
      "\"Banner Ocotillo Medical Center\",\"Arizona\"\n",
      "\"Banner Payson Medical Center\",\"Arizona\"\n",
      "\"Banner Rehabilitation Hospitals\",\"Arizona\"\n",
      "\"Banner Thunderbird Medical Center\",\"Arizona\"\n",
      "\"Page Hospital\",\"Arizona\"\n",
      "\"Banner Lassen Medical Center\",\"California\"\n",
      "\"Banner Fort Collins Medical Center\",\"Colorado\"\n",
      "\"McKee Medical Center\",\"Colorado\"\n",
      "\"North Colorado Medical Center\",\"Colorado\"\n",
      "\"Sterling Regional Medical Center\",\"Colorado\"\n",
      "\"East Morgan County Hospital\",\"Colorado\"\n",
      "\"Ogallala Community Hospital\",\"Nebraska\"\n",
      "\"Banner Churchill Community Hospital\",\"Nevada\"\n",
      "\"Banner Wyoming Medical Center Central Campus\",\"Wyoming\"\n",
      "\"Banner Wyoming Medical Center East Campus\",\"Wyoming\"\n",
      "\"Community Hospital\",\"Wyoming\"\n",
      "\"Washakie Medical Center\",\"Wyoming\"\n",
      "\"Platte County Memorial Hospital\",\"Wyoming\"\n",
      "\"Arizona\",\"State-Specific Regulations\"\n",
      "\"California\",\"State-Specific Regulations\"\n",
      "\"Colorado\",\"State-Specific Regulations\"\n",
      "\"Nebraska\",\"State-Specific Regulations\"\n",
      "\"Nevada\",\"State-Specific Regulations\"\n",
      "\"Wyoming\",\"State-Specific Regulations\"\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def parse_banner(url):\n",
    "    \"\"\"(url) -> list\n",
    "    This function parses the underlying HTML to create a list of all hospitals along with the\n",
    "    city associated with them \n",
    "    \"\"\"\n",
    "\n",
    "# Note that you'll need to fetch the data using the following syntax to include headers\n",
    "# that make the web server think you're a real web browser.\n",
    "headers = { \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36\" }\n",
    "response = requests.get('https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency', headers=headers)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "resp_div = soup.find_all('div', {\"class\":\"col-md-8\"})[0]\n",
    "for hospital_names in resp_div.find_all('ul'): \n",
    "    statename = hospital_names.previous_sibling.previous_sibling.string \n",
    "    for hospital in hospital_names.find_all('li'):\n",
    "          print('\"' + hospital.text + '\",\"' + statename + '\"')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n"
     ]
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.run_docstring_examples(parse_banner, globals(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b50f7d3d19d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbanner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_banner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbanner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Length of result should have been 38, but {} returned.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbanner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mbanner\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Arizona'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Wrong data found in the first result item: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbanner\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "banner = parse_banner('https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency')\n",
    "assert len(banner)==38, 'Length of result should have been 38, but {} returned.'.format(len(banner))\n",
    "assert banner[0][1]=='Arizona', 'Wrong data found in the first result item: {}'.format(banner[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 33.2 Using a REST API (from GitHub.com)\n",
    "\n",
    "Many websites provide something called a REST API to access information from their site programatically, rather than relying on HTML.  One example is GitHub.com, whose API allows you do to things like \"list all the public repositories for a user.\"\n",
    "\n",
    "The documentation for GitHub.com's REST API can be found here: https://docs.github.com/en/rest/guides/getting-started-with-the-rest-api\n",
    "\n",
    "Create a function called **repo_summary(user)** that takes a GitHub.com user name as it's parameter and retrieves a list of all the repositories you can see for that user.  The specific documentation for the this kind of request can be found here: https://docs.github.com/en/rest/reference/repos#list-repositories-for-a-user. Make sure your function is well documented with a docstring and includes a simple test to verify that you get back 12 repositories when querying for the repositories for user **paulboal**.\n",
    "\n",
    "I've provided a related example to help you out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This information is about paulboal. His website is www.amitechsolutions.com.\n"
     ]
    }
   ],
   "source": [
    "# Example -- this example of code shows how to get basic information on the user paulboal\n",
    "# For your solution, make sure you meet the requirements in the instructions above.\n",
    "\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://api.github.com/users/paulboal')\n",
    "data = response.json()\n",
    "\n",
    "print('This information is about {}. His website is {}.'.format(data.get('login'), data.get('blog')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ajaxterm/ncms_hospital_compare/ncollibra-scripts/ncoronadatascraper/nhadoop-heuristicsminer/nhds5210-2021/nhds5210-2022/njupyterhub-nbgrader/nnppes_demo/npexpect-curses/nscm-products/ntdwi-accelerate-2017-python\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Your code Here\n",
    "def repo_summary(user): \n",
    "    \"\"\"(user) -> list\n",
    "    This function takes a github.com username as it's parameter and retrieves a list \n",
    "    of all repositories one can see for that user. \n",
    "    \n",
    "    >>> len(repo_summary('paulboal')) \n",
    "    12\n",
    "    \"\"\"\n",
    "    response = requests.get('https://api.github.com/users/'+user+'/repos')\n",
    "    repos = response.json()\n",
    "    reposit = [] \n",
    "    for repo in repos: \n",
    "        reposit.append(repo['name'])\n",
    "    return reposit\n",
    "\n",
    "print(*repo_summary('paulboal'), sep = \"/n\")\n",
    "print(len(repo_summary('paulboal')))\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest\n",
    "doctest.run_docstring_examples(repo_summary, globals(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = repo_summary('paulboal')\n",
    "assert len(repos)==12, 'Expecing 12, but {} were found'.format(len(repos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 33.3 Find Something of Your Own\n",
    "\n",
    "Do some web searches and find an HTML page with some data that is interesting to something you're studying.  You can extract and parse that information using either BeautifulSoup or Pandas.  If you're using Pandas, then do something interesting to format and structure your data.  If you're using BeautifulSoup, you'll just need to do the work of parsing the data out of HTML -- that's hard enough!\n",
    "\n",
    "You don't need to build this as a function.  Just use notebook cells as I've done above.  You will be graded based on _style_.  Use variable names that make sense for your problem / solution. Cleanup anything you don't need before you submit your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "\"\"\" This code is supposed to extract the table of contents from the following url\"\"\"\n",
    "\n",
    "url = \"https://www.simplilearn.com/what-skills-do-i-need-to-become-a-data-scientist-article\"\n",
    "headers = { \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36\" }\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "allheaders = soup.find_all('h2')\n",
    "print(\"LIST OF HEADERS for the article : \" + url)\n",
    "print(\"=====================================================\")\n",
    "for header in allheaders:\n",
    "    print(header.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Check your work above\n",
    "\n",
    "If you didn't get them all correct, take a few minutes to think through those that aren't correct.\n",
    "\n",
    "\n",
    "## Submitting Your Work\n",
    "\n",
    "In order to submit your work, you'll need to use the `git` command line program to **add** your homework file (this file) to your local repository, **commit** your changes to your local repository, and then **push** those changes up to github.com.  From there, I'll be able to **pull** the changes down and do my grading.  I'll provide some feedback, **commit** and **push** my comments back to you.  Next week, I'll show you how to **pull** down my comments.\n",
    "\n",
    "To run through everything one last time and submit your work:\n",
    "1. Use the `Kernel` -> `Restart Kernel and Run All Cells` menu option to run everything from top to bottom and stop here.\n",
    "2. Follow the instruction on the prompt below to either ssave and submit your work, or continue working.\n",
    "\n",
    "If anything fails along the way with this submission part of the process, let me know.  I'll help you troubleshoort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Are you ready to submit your work?\n",
      "1. Click the Save icon (or do Ctrl-S / Cmd-S)\n",
      "2. Type \"yes\" or \"no\" below\n",
      "3. Press Enter\n",
      "\n",
      " yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 0d22e18] Submitting the week 7 programming exercises\n",
      " 2 files changed, 405 insertions(+), 3 deletions(-)\n",
      " create mode 100644 week07/week07_assignment_2.ipynb\n",
      "Counting objects: 5, done.\n",
      "Delta compression using up to 2 threads.\n",
      "Compressing objects: 100% (5/5), done.\n",
      "Writing objects: 100% (5/5), 5.21 KiB | 5.21 MiB/s, done.\n",
      "Total 5 (delta 2), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
      "To github.com:asahu123/hds5210-2022.git\n",
      "   038e180..0d22e18  main -> main\n"
     ]
    }
   ],
   "source": [
    "a=input('''\n",
    "Are you ready to submit your work?\n",
    "1. Click the Save icon (or do Ctrl-S / Cmd-S)\n",
    "2. Type \"yes\" or \"no\" below\n",
    "3. Press Enter\n",
    "\n",
    "''')\n",
    "\n",
    "if a=='yes':\n",
    "    !git add week07_assignment_2.ipynb\n",
    "    !git commit -a -m \"Submitting the week 7 programming exercises\"\n",
    "    !git push\n",
    "else:\n",
    "    print('''\n",
    "    \n",
    "OK. We can wait.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
